{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f19fe218-8272-4a78-95dc-b45c7944d26d",
   "metadata": {},
   "source": [
    "# Building and deploying machine learning solutions with Vertex AI: Challenge Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91e5394-d8e8-4b56-99a1-f7c3b0f574f4",
   "metadata": {},
   "source": [
    "This Challenge Lab is recommended for students who have enrolled in the [**Building and deploying machine learning solutions with Vertex AI**](). You will be given a scenario and a set of tasks. Instead of following step-by-step instructions, you will use the skills learned from the labs in the quest to figure out how to complete the tasks on your own! An automated scoring system (shown on the Qwiklabs lab instructions page) will provide feedback on whether you have completed your tasks correctly.\n",
    "\n",
    "When you take a Challenge Lab, you will not be taught Google Cloud concepts. To build the solution to the challenge presented, use skills learned from the labs in the Quest this challenge lab is part of. You are expected to extend your learned skills and complete all the **`TODO:`** comments in this notebook.\n",
    "\n",
    "Are you ready for the challenge?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4908fb9b-2048-48fc-a42c-2fdf76aea51e",
   "metadata": {},
   "source": [
    "## Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefbdce5-4287-4740-bdbd-729d15d8ab7f",
   "metadata": {},
   "source": [
    "You were recently hired as a Machine Learning Engineer at a startup movie review website. Your manager has tasked you with building a machine learning model to classify the sentiment of user movie reviews as positive or negative. These predictions will be used as an input in downstream movie rating systems and to surface top supportive and critical reviews on the movie website application. The challenge: your business requirements are that you have just 6 weeks to productionize a model that achieves great than 75% accuracy to improve upon an existing bootstrapped solution. Furthermore, after doing some exploratory analysis in your startup's data warehouse, you found that you only have a small dataset of 50k text reviews to build a higher performing solution.\n",
    "\n",
    "To build and deploy a high performance machine learning model with limited data quickly, you will walk through training and deploying a custom TensorFlow BERT sentiment classifier for online predictions on Google Cloud's [Vertex AI](https://cloud.google.com/vertex-ai) platform. Vertex AI is Google Cloud's next generation machine learning development platform where you can leverage the latest ML pre-built components and AutoML to significantly enhance your development productivity, scale your workflow and decision making with your data, and accelerate time to value.\n",
    "\n",
    "![Vertex AI: Challenge Lab](./images/vertex-challenge-lab.png \"Vertex Challenge Lab\")\n",
    "\n",
    "First, you will progress through a typical experimentation workflow where you will build your model from pre-trained BERT components from TF-Hub and `tf.keras` classification layers to train and evaluate your model in a Vertex Notebook. You will then package your model code into a Docker container to train on Google Cloud's Vertex AI. Lastly, you will define and run a Kubeflow Pipeline on Vertex Pipelines that trains and deploys your model to a Vertex Endpoint that you will query for online predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8955d75d-cfa4-43af-8783-d2aec5ae525e",
   "metadata": {},
   "source": [
    "## Learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b386b37c-2ce1-4b1f-8c90-b83bda6075c8",
   "metadata": {},
   "source": [
    "* Train a TensorFlow model locally in a hosted [**Vertex Notebook**](https://cloud.google.com/vertex-ai/docs/general/notebooks?hl=sv).\n",
    "* Containerize your training code with [**Cloud Build**](https://cloud.google.com/build) and push it to [**Google Cloud Artifact Registry**](https://cloud.google.com/artifact-registry).\n",
    "* Define a pipeline using the [**Kubeflow Pipelines (KFP) V2 SDK**](https://www.kubeflow.org/docs/components/pipelines/sdk/v2/v2-compatibility) to train and deploy your model on [**Vertex Pipelines**](https://cloud.google.com/vertex-ai/docs/pipelines).\n",
    "* Query your model on a [**Vertex Endpoint**](https://cloud.google.com/vertex-ai/docs/predictions/getting-predictions) using online predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d23538a-e809-4747-9bd4-5610f8544ea1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4480c8-710c-40dd-93c2-c51e67e59760",
   "metadata": {},
   "source": [
    "### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e0feaf4-9849-4636-b736-d3cd8a051579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/jupyter/.local/bin\n"
     ]
    }
   ],
   "source": [
    "# Add installed library dependencies to Python PATH variable.\n",
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f68df5dd-c456-4edd-8f58-71597f10c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and set PROJECT_ID and REGION environment variables.\n",
    "# TODO: fill in PROJECT_ID.\n",
    "PROJECT_ID = \"qwiklabs-gcp-03-80c91a5be9c5\"\n",
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3912f9-6c12-439f-8613-cc60c286b3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a globally unique Google Cloud Storage bucket for artifact storage.\n",
    "GCS_BUCKET = \"gs://{}-vertex-challenge-lab\".format(PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4931ae91-3ba1-437a-9c37-187a41a3d227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://qwiklabs-gcp-03-80c91a5be9c5-vertex-challenge-lab/...\n"
     ]
    }
   ],
   "source": [
    "!gsutil mb -l $REGION $GCS_BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ebbc2b-21ad-47f0-829f-9beba0deba9d",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf558fc-d0fc-4452-8281-7d7cd0cffe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.7.0 and strictly below 2.10.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.6.4 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "\n",
    "# TensorFlow model building libraries.\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# Re-create the AdamW optimizer used in the original BERT paper.\n",
    "from official.nlp import optimization  \n",
    "\n",
    "# Libraries for data and plot model training metrics.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import the Vertex AI Python SDK.\n",
    "from google.cloud import aiplatform as vertexai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d296167a-13b9-4895-be8b-b3b49fad5d47",
   "metadata": {},
   "source": [
    "### Initialize Vertex AI Python SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c178b0-0edb-4e4b-abb4-d3cc0bd676de",
   "metadata": {},
   "source": [
    "Initialize the Vertex AI Python SDK with your GCP Project, Region, and Google Cloud Storage Bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a43371e-2c64-4a76-8698-fa768043dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexai.init(project=PROJECT_ID, location=REGION, staging_bucket=GCS_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2917411-811c-46dd-8eda-e8ef579c568d",
   "metadata": {},
   "source": [
    "## Build and train your model locally in a Vertex Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efc8cc5-ed5e-457a-b5f5-475bacca4611",
   "metadata": {},
   "source": [
    "Note: this lab adapts and extends the official [TensorFlow BERT text classification tutorial](https://www.tensorflow.org/text/tutorials/classify_text_with_bert) to utilize Vertex AI services. See the tutorial for additional coverage on fine-tuning BERT models using TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3338a818-18e5-4b0b-b37d-b387577a08ef",
   "metadata": {},
   "source": [
    "### Lab dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdfb91d-6060-4d00-a1c3-299ee6027b76",
   "metadata": {},
   "source": [
    "In this lab, you will use the [Large Movie Review Dataset](https://ai.stanford.edu/~amaas/data/sentiment) that contains the text of 50,000 movie reviews from the Internet Movie Database. These are split into 25,000 reviews for training and 25,000 reviews for testing. The training and testing sets are balanced, meaning they contain an equal number of positive and negative reviews. Data ingestion and processing code has been provided for you below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef491df4-c35f-4555-a6b6-96114c3d3c6e",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ee70d2c-c0e3-4c75-9bc6-b42dad6c7267",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_URL = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
    "LOCAL_DATA_DIR = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c889f275-ce52-4108-9f7f-7cf824184f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(data_url, local_data_dir):\n",
    "    \"\"\"Download dataset.\n",
    "    Args:\n",
    "      data_url(str): Source data URL path.\n",
    "      local_data_dir(str): Local data download directory path.\n",
    "    Returns:\n",
    "      dataset_dir(str): Local unpacked data directory path.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(local_data_dir):\n",
    "        os.makedirs(local_data_dir)\n",
    "    \n",
    "    dataset = tf.keras.utils.get_file(\n",
    "      fname=\"aclImdb_v1.tar.gz\",\n",
    "      origin=data_url,\n",
    "      untar=True,\n",
    "      cache_dir=local_data_dir,\n",
    "      cache_subdir=\"\"\n",
    "    )\n",
    "    \n",
    "    dataset_dir = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
    "    \n",
    "    train_dir = os.path.join(dataset_dir, \"train\")\n",
    "    \n",
    "    # Remove unused folders to make it easier to load the data.\n",
    "    remove_dir = os.path.join(train_dir, \"unsup\")\n",
    "    shutil.rmtree(remove_dir)\n",
    "    \n",
    "    return dataset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98f906a4-64a0-45ae-b376-757ef0f661fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
      "84131840/84125825 [==============================] - 2s 0us/step\n",
      "84140032/84125825 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "DATASET_DIR = download_data(data_url=DATA_URL, local_data_dir=LOCAL_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d95a61fa-cf55-470f-9837-c783c4bcccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to iteratively add data pipeline and model training hyperparameters.\n",
    "HPARAMS = {\n",
    "    \"seed\": 42,       # Set a random sampling seed to prevent data leakage in data splits from files.\n",
    "    \"batch-size\": 32  # Number of training and inference examples.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aeea425-d288-44a7-9958-f2b1f48f9c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(dataset_dir, hparams):\n",
    "    \"\"\"Load pre-split tf.datasets.\n",
    "    Args:\n",
    "      hparams(dict): A dictionary containing model training arguments.\n",
    "    Returns:\n",
    "      raw_train_ds(tf.dataset): Train split dataset (20k examples).\n",
    "      raw_val_ds(tf.dataset): Validation split dataset (5k examples).\n",
    "      raw_test_ds(tf.dataset): Test split dataset (25k examples).\n",
    "    \"\"\"    \n",
    "\n",
    "    raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        os.path.join(dataset_dir, 'train'),\n",
    "        batch_size=hparams['batch-size'],\n",
    "        validation_split=0.2,\n",
    "        subset='training',\n",
    "        seed=hparams['seed']\n",
    "    )    \n",
    "\n",
    "    raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        os.path.join(dataset_dir, 'train'),\n",
    "        batch_size=hparams['batch-size'],\n",
    "        validation_split=0.2,\n",
    "        subset='validation',\n",
    "        seed=hparams['seed']\n",
    "    )\n",
    "\n",
    "    raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        os.path.join(dataset_dir, 'test'),\n",
    "        batch_size=hparams['batch-size']\n",
    "    )\n",
    "    \n",
    "    return raw_train_ds, raw_val_ds, raw_test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ff05aa4-d299-4c80-a29a-43c6bc3ac152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 10:11:16.749889: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "raw_train_ds, raw_val_ds, raw_test_ds = load_datasets(DATASET_DIR, HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50ee40c0-9e37-483c-98f5-dcdb467a2bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "CLASS_NAMES = raw_train_ds.class_names\n",
    "\n",
    "train_ds = raw_train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = raw_val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = raw_test_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f5734e-d97c-484d-9f52-f6fb4e153ef0",
   "metadata": {},
   "source": [
    "Let's print a few example reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d794068-817c-4cb8-8e4c-c49860d0c92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0: b'\"Pandemonium\" is a horror movie spoof that comes off more stupid than funny. Believe me when I tell you, I love comedies. Especially comedy spoofs. \"Airplane\", \"The Naked Gun\" trilogy, \"Blazing Saddles\", \"High Anxiety\", and \"Spaceballs\" are some of my favorite comedies that spoof a particular genre. \"Pandemonium\" is not up there with those films. Most of the scenes in this movie had me sitting there in stunned silence because the movie wasn\\'t all that funny. There are a few laughs in the film, but when you watch a comedy, you expect to laugh a lot more than a few times and that\\'s all this film has going for it. Geez, \"Scream\" had more laughs than this film and that was more of a horror film. How bizarre is that?<br /><br />*1/2 (out of four)'\n",
      "Label : 0 (neg)\n",
      "Review 1: b\"David Mamet is a very interesting and a very un-equal director. His first movie 'House of Games' was the one I liked best, and it set a series of films with characters whose perspective of life changes as they get into complicated situations, and so does the perspective of the viewer.<br /><br />So is 'Homicide' which from the title tries to set the mind of the viewer to the usual crime drama. The principal characters are two cops, one Jewish and one Irish who deal with a racially charged area. The murder of an old Jewish shop owner who proves to be an ancient veteran of the Israeli Independence war triggers the Jewish identity in the mind and heart of the Jewish detective.<br /><br />This is were the flaws of the film are the more obvious. The process of awakening is theatrical and hard to believe, the group of Jewish militants is operatic, and the way the detective eventually walks to the final violent confrontation is pathetic. The end of the film itself is Mamet-like smart, but disappoints from a human emotional perspective.<br /><br />Joe Mantegna and William Macy give strong performances, but the flaws of the story are too evident to be easily compensated.\"\n",
      "Label : 0 (neg)\n",
      "Review 2: b'Great documentary about the lives of NY firefighters during the worst terrorist attack of all time.. That reason alone is why this should be a must see collectors item.. What shocked me was not only the attacks, but the\"High Fat Diet\" and physical appearance of some of these firefighters. I think a lot of Doctors would agree with me that,in the physical shape they were in, some of these firefighters would NOT of made it to the 79th floor carrying over 60 lbs of gear. Having said that i now have a greater respect for firefighters and i realize becoming a firefighter is a life altering job. The French have a history of making great documentary\\'s and that is what this is, a Great Documentary.....'\n",
      "Label : 1 (pos)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 10:11:19.258396: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "    \n",
    "    for i in range(3):\n",
    "        \n",
    "        print(f'Review {i}: {text_batch.numpy()[i]}')\n",
    "        \n",
    "        label = label_batch.numpy()[i]\n",
    "        \n",
    "        print(f'Label : {label} ({CLASS_NAMES[label]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3e6686-2fa1-453c-8259-8e5a87cba023",
   "metadata": {},
   "source": [
    "### Choose a pre-trained BERT model to fine-tune for higher accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3502ad71-5747-4a11-9122-0b5c7b2049cd",
   "metadata": {},
   "source": [
    "[**Bidirectional Encoder Representations from Transformers (BERT)**](https://arxiv.org/abs/1810.04805v2) is a transformer-based text representation model pre-trained on massive datasets (3+ billion words) that can be fine-tuned for state-of-the art results on many natural language processing (NLP) tasks. Since release in 2018 by Google researchers, its has transformed the field of NLP research and come to form a core part of significant improvements to [Google Search](https://www.blog.google/products/search/search-language-understanding-bert). \n",
    "\n",
    "To meet your business requirements of achieving higher accuracy on a small dataset (20k training examples), you will use a technique called transfer learning to combine a pre-trained BERT encoder and classification layers to fine tune a new higher performing model for binary sentiment classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd347cc-5f87-4b89-8833-6df850729ec3",
   "metadata": {},
   "source": [
    "For this lab, you will use a smaller BERT model that trades some accuracy for faster training times.\n",
    "\n",
    "The Small BERT models are instances of the original BERT architecture with a smaller number L of layers (i.e., residual blocks) combined with a smaller hidden size H and a matching smaller number A of attention heads, as published by\n",
    "\n",
    "Iulia Turc, Ming-Wei Chang, Kenton Lee, Kristina Toutanova: [\"Well-Read Students Learn Better: On the Importance of Pre-training Compact Models\"](https://arxiv.org/abs/1908.08962), 2019.\n",
    "\n",
    "They have the same general architecture but fewer and/or smaller Transformer blocks, which lets you explore tradeoffs between speed, size and quality.\n",
    "\n",
    "The following preprocessing and encoder models in the TensorFlow 2 SavedModel format use the implementation of BERT from the [TensorFlow Models Github repository](https://github.com/tensorflow/models/tree/master/official/nlp/bert) with the trained weights released by the authors of Small BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22196658-1c30-49c7-8485-5d933fc8988e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF Hub BERT modules.\n",
    "HPARAMS.update({    \n",
    "    \"tfhub-bert-preprocessor\": \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\",   \n",
    "    \"tfhub-bert-encoder\": \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc50b93a-df95-47d9-bc14-14502ae4eb54",
   "metadata": {},
   "source": [
    "Text inputs need to be transformed to numeric token ids and arranged in several Tensors before being input to BERT. TensorFlow Hub provides a matching preprocessing model for each of the BERT models discussed above, which implements this transformation using TF ops from the TF.text library. Since this text preprocessor is a TensorFlow model, It can be included in your model directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780e50df-9d35-4116-a167-8353046bf6b9",
   "metadata": {},
   "source": [
    "For fine-tuning, you will use the same optimizer that BERT was originally trained with: the \"Adaptive Moments\" (Adam). This optimizer minimizes the prediction loss and does regularization by weight decay (not using moments), which is also known as [AdamW](https://arxiv.org/abs/1711.05101)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26396cb1-fc24-4e96-bef2-6fc8e2d500a6",
   "metadata": {},
   "source": [
    "For the learning rate `initial-learning-rate`, you will use the same schedule as BERT pre-training: linear decay of a notional initial learning rate, prefixed with a linear warm-up phase over the first 10% of training steps `n_warmup_steps`. In line with the BERT paper, the initial learning rate is smaller for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b634139-a0d1-41e7-be23-c6e580a4f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training hyperparameters for fine tuning and regularization.\n",
    "HPARAMS.update({    \n",
    "    \"epochs\": 3,\n",
    "    \"initial-learning-rate\": 3e-5,\n",
    "    \"dropout\": 0.1 \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e415aeb-5ab2-42ac-904a-ae0649d45a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:using Adamw optimizer\n",
      "INFO:absl:gradient_clip_norm=1.000000\n"
     ]
    }
   ],
   "source": [
    "epochs = HPARAMS['epochs']\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "n_train_steps = steps_per_epoch * epochs\n",
    "n_warmup_steps = int(0.1 * n_train_steps)    \n",
    "\n",
    "OPTIMIZER = optimization.create_optimizer(\n",
    "    init_lr=HPARAMS['initial-learning-rate'],\n",
    "    num_train_steps=n_train_steps,\n",
    "    num_warmup_steps=n_warmup_steps,\n",
    "    optimizer_type='adamw'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005b4646-ce95-47c4-b1f7-886f59980386",
   "metadata": {},
   "source": [
    "### Build and compile a TensorFlow BERT sentiment classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80920377-4596-4dbd-8eb7-8580327fdb24",
   "metadata": {},
   "source": [
    "Next, you will define and compile your model by assembling pre-built TF-Hub components and tf.keras layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "289da96f-2aad-4c34-85ce-5916ea98778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_text_classifier(hparams, optimizer):\n",
    "    \"\"\"Define and compile a TensorFlow BERT sentiment classifier.\n",
    "    Args:\n",
    "      hparams(dict): A dictionary containing model training arguments.\n",
    "    Returns:\n",
    "      model(tf.keras.Model): A compiled TensorFlow model.\n",
    "    \"\"\"\n",
    "    text_input = tf.keras.layers.Input(\n",
    "        shape=(), \n",
    "        dtype=tf.string, \n",
    "        name='text'\n",
    "    )\n",
    "    \n",
    "    # TODO: Add a hub.KerasLayer for BERT text preprocessing using the hparams dict. \n",
    "    # Name the layer 'preprocessing' and store in the variable preprocessor.\n",
    "    preprocessor = hub.KerasLayer(\n",
    "        hparams['tfhub-bert-preprocessor'],\n",
    "        name='preprocessing'\n",
    "    )\n",
    "    \n",
    "    encoder_inputs = preprocessor(text_input)\n",
    "    \n",
    "    # TODO: Add a trainable hub.KerasLayer for BERT text encoding using the hparams dict.\n",
    "    # Name the layer 'BERT_encoder' and store in the variable encoder.\n",
    "    encoder = hub.KerasLayer(\n",
    "        hparams['tfhub-bert-encoder'], \n",
    "        trainable=True, \n",
    "        name='BERT_encoder'\n",
    "    )\n",
    "    \n",
    "    outputs = encoder(encoder_inputs)\n",
    "    \n",
    "    # For the fine-tuning you are going to use the `pooled_output` array which represents each input sequence as a whole. The shape is [batch_size, H]. \n",
    "    # You can think of this as an embedding for the entire movie review.\n",
    "    classifier = outputs['pooled_output']\n",
    "    \n",
    "    # Add dropout to prevent overfitting during model fine-tuning.\n",
    "    classifier = tf.keras.layers.Dropout(hparams['dropout'], name='dropout')(classifier)\n",
    "    classifier = tf.keras.layers.Dense(1, activation=None, name='classifier')(classifier)\n",
    "    model = tf.keras.Model(text_input, classifier, name='bert-sentiment-classifier')\n",
    "    \n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    metrics = tf.metrics.BinaryAccuracy()    \n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=metrics\n",
    "    )    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "036b72cc-9e1c-49c9-8a90-7b09b6108f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'.\n",
      "INFO:absl:Downloaded https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3, Total size: 1.96MB\n",
      "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'.\n",
      "INFO:absl:Downloading TF-Hub Module 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2'.\n",
      "INFO:absl:Downloaded https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2, Total size: 19.27MB\n",
      "INFO:absl:Downloaded TF-Hub Module 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2'.\n"
     ]
    }
   ],
   "source": [
    "model = build_text_classifier(HPARAMS, OPTIMIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8198df2-c15a-4f79-a154-83c941aba5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize your fine-tuned BERT sentiment classifier.\n",
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acfeb71d-4e19-4759-8f5c-293c8c7cee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_REVIEW = ['this is such an amazing movie!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1c2112f-9f04-470e-8636-38ea948cba9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.30916706]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "BERT_RAW_RESULT = model(tf.constant(TEST_REVIEW))\n",
    "print(BERT_RAW_RESULT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53dd9fa-d0a4-46ab-a123-3065b8fde7c8",
   "metadata": {},
   "source": [
    "### Train and evaluate your BERT sentiment classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1f008fc-f696-4b71-9011-2a897d268795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save your BERT sentiment classifier locally. \n",
    "# Hint: Save it to './bert-sentiment-classifier-local'. Note the key name in model.save().\n",
    "HPARAMS.update({\"model-dir\": \"./bert-sentiment-classifier-local\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efd08f3-988f-408a-b694-af4702de85ba",
   "metadata": {},
   "source": [
    "**Note:** training your model locally will take about 8-10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24660956-d60a-4c25-a654-7b192a01a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_evaluate(hparams):\n",
    "    \"\"\"Train and evaluate TensorFlow BERT sentiment classifier.\n",
    "    Args:\n",
    "      hparams(dict): A dictionary containing model training arguments.\n",
    "    Returns:\n",
    "      history(tf.keras.callbacks.History): Keras callback that records training event history.\n",
    "    \"\"\"\n",
    "    # dataset_dir = download_data(data_url, local_data_dir)\n",
    "    raw_train_ds, raw_val_ds, raw_test_ds = load_datasets(DATASET_DIR, hparams)\n",
    "    \n",
    "    train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    val_ds = raw_val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    test_ds = raw_test_ds.cache().prefetch(buffer_size=AUTOTUNE)     \n",
    "    \n",
    "    epochs = hparams['epochs']\n",
    "    steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "    n_train_steps = steps_per_epoch * epochs\n",
    "    n_warmup_steps = int(0.1 * n_train_steps)    \n",
    "    \n",
    "    optimizer = optimization.create_optimizer(\n",
    "        init_lr=hparams['initial-learning-rate'],\n",
    "        num_train_steps=n_train_steps,\n",
    "        num_warmup_steps=n_warmup_steps,\n",
    "        optimizer_type='adamw'\n",
    "    )    \n",
    "    \n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    \n",
    "    with mirrored_strategy.scope(): model = build_text_classifier(hparams=hparams, optimizer=optimizer)\n",
    "    \n",
    "    logging.info(model.summary())\n",
    "        \n",
    "    history = model.fit(x=train_ds, validation_data=val_ds, epochs=epochs)  \n",
    "    \n",
    "    logging.info(\"Test accuracy: %s\", model.evaluate(test_ds))\n",
    "\n",
    "    # Export Keras model in TensorFlow SavedModel format.\n",
    "    model.save(hparams['model-dir'])\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0549e700-bf6a-415a-bb35-01150d9535e5",
   "metadata": {},
   "source": [
    "Based on the `History` object returned by `model.fit()`. You can plot the training and validation loss for comparison, as well as the training and validation accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f59cab23-fbf0-44d2-9ee0-e2dd83390fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "INFO:absl:using Adamw optimizer\n",
      "INFO:absl:gradient_clip_norm=1.000000\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Model: \"bert-sentiment-classifier\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "preprocessing (KerasLayer)      {'input_mask': (None 0           text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "BERT_encoder (KerasLayer)       {'pooled_output': (N 4385921     preprocessing[0][0]              \n",
      "                                                                 preprocessing[0][1]              \n",
      "                                                                 preprocessing[0][2]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           BERT_encoder[0][3]               \n",
      "__________________________________________________________________________________________________\n",
      "classifier (Dense)              (None, 1)            129         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,386,050\n",
      "Trainable params: 4,386,049\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n",
      "INFO:root:None\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 10:11:34.521072: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2022-07-07 10:11:34.572017: W tensorflow/core/framework/dataset.cc:679] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - ETA: 0s - loss: 0.6307 - binary_accuracy: 0.6227"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 10:16:44.382614: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "2022-07-07 10:16:44.464174: W tensorflow/core/framework/dataset.cc:679] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 343s 538ms/step - loss: 0.6307 - binary_accuracy: 0.6227 - val_loss: 0.5115 - val_binary_accuracy: 0.7262\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 10:17:18.039089: W tensorflow/core/framework/dataset.cc:679] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - ETA: 0s - loss: 0.4917 - binary_accuracy: 0.7518"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 10:22:23.372286: W tensorflow/core/framework/dataset.cc:679] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 336s 538ms/step - loss: 0.4917 - binary_accuracy: 0.7518 - val_loss: 0.4572 - val_binary_accuracy: 0.7644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 10:22:54.235015: W tensorflow/core/framework/dataset.cc:679] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3\n",
      "625/625 [==============================] - ETA: 0s - loss: 0.4516 - binary_accuracy: 0.7832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 10:28:45.079690: W tensorflow/core/framework/dataset.cc:679] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 335s 536ms/step - loss: 0.4516 - binary_accuracy: 0.7832 - val_loss: 0.4575 - val_binary_accuracy: 0.7702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 10:29:14.753060: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_1\"\n",
      "op: \"TensorSliceDataset\"\n",
      "input: \"Placeholder/_0\"\n",
      "attr {\n",
      "  key: \"Toutput_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_STRING\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 157s 200ms/step - loss: 0.4566 - binary_accuracy: 0.7762\n",
      "INFO:root:Test accuracy: [0.4566044509410858, 0.7762399911880493]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-07 10:32:37.813942: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 165). These functions will not be directly callable after loading.\n",
      "INFO:tensorflow:Assets written to: ./bert-sentiment-classifier-local/assets\n",
      "INFO:tensorflow:Assets written to: ./bert-sentiment-classifier-local/assets\n"
     ]
    }
   ],
   "source": [
    "history = train_evaluate(HPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91980420-8451-4869-b189-2b3693131ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys())\n",
    "\n",
    "acc = history_dict['binary_accuracy']\n",
    "val_acc = history_dict['val_binary_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "\n",
    "# plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fcbcff-18d5-4448-b695-fd6bf3189c2f",
   "metadata": {},
   "source": [
    "In this plot, the red lines represent the training loss and accuracy, and the blue lines are the validation loss and accuracy. Based on the plots above, you should see model accuracy of around 78-80% which exceeds your business requirements target of greater than 75% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fc3fed-aa4c-40b2-8c44-19be21ba4689",
   "metadata": {},
   "source": [
    "## Containerize your model code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3905338-288b-4565-9abb-9053d7559315",
   "metadata": {},
   "source": [
    "Now that you trained and evaluated your model locally in a Vertex Notebook as part of an experimentation workflow, your next step is to train and deploy your model on Google Cloud's Vertex AI platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbb61ec-cb3c-43bd-9d75-9d61ff52848e",
   "metadata": {},
   "source": [
    "To train your BERT classifier on Google Cloud, you will you will package your Python training scripts and write a Dockerfile that contains instructions on your ML model code, dependencies, and execution instructions. You will build your custom container with Cloud Build, whose instructions are specified in `cloudbuild.yaml` and publish your container to your Artifact Registry. This workflow gives you the opportunity to use the same container to run as part of a portable and scalable [Vertex Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/introduction) workflow. \n",
    "\n",
    "\n",
    "You will walk through creating the following project structure for your ML mode code:\n",
    "```\n",
    "|--/bert-sentiment-classifier\n",
    "   |--/trainer\n",
    "      |--__init__.py\n",
    "      |--model.py\n",
    "      |--task.py\n",
    "   |--Dockerfile\n",
    "   |--cloudbuild.yaml\n",
    "   |--requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a033e3c3-9dad-49d8-b53c-fd48113a8f90",
   "metadata": {},
   "source": [
    "### 1. Write a `model.py` training script\n",
    "\n",
    "First, you will tidy up your local TensorFlow model training code from above into a training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0129184d-15ed-4ebe-bbdc-6c2687eb18cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"bert-sentiment-classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2594afe7-b9e0-4957-9156-d2e595fde62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting bert-sentiment-classifier/trainer/model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {MODEL_DIR}/trainer/model.py\n",
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "import tensorflow_hub as hub\n",
    "from official.nlp import optimization\n",
    "\n",
    "DATA_URL = 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "LOCAL_DATA_DIR = './tmp/data'\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "def download_data(data_url, local_data_dir):\n",
    "    \"\"\"Download dataset.\n",
    "    Args:\n",
    "      data_url(str): Source data URL path.\n",
    "      local_data_dir(str): Local data download directory path.\n",
    "    Returns:\n",
    "      dataset_dir(str): Local unpacked data directory path.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(local_data_dir):\n",
    "        os.makedirs(local_data_dir)\n",
    "    \n",
    "    dataset = tf.keras.utils.get_file(\n",
    "      fname='aclImdb_v1.tar.gz',\n",
    "      origin=data_url,\n",
    "      untar=True,\n",
    "      cache_dir=local_data_dir,\n",
    "      cache_subdir=\"\"\n",
    "    )\n",
    "    \n",
    "    dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
    "    \n",
    "    train_dir = os.path.join(dataset_dir, 'train')\n",
    "    \n",
    "    # Remove unused folders to make it easier to load the data.\n",
    "    remove_dir = os.path.join(train_dir, 'unsup')\n",
    "    shutil.rmtree(remove_dir)\n",
    "    \n",
    "    return dataset_dir\n",
    "\n",
    "def load_datasets(dataset_dir, hparams):\n",
    "    \"\"\"Load pre-split tf.datasets.\n",
    "    Args:\n",
    "      hparams(dict): A dictionary containing model training arguments.\n",
    "    Returns:\n",
    "      raw_train_ds(tf.dataset): Train split dataset (20k examples).\n",
    "      raw_val_ds(tf.dataset): Validation split dataset (5k examples).\n",
    "      raw_test_ds(tf.dataset): Test split dataset (25k examples).\n",
    "    \"\"\"    \n",
    "\n",
    "    raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        os.path.join(dataset_dir, 'train'),\n",
    "        batch_size=hparams['batch-size'],\n",
    "        validation_split=0.2,\n",
    "        subset='training',\n",
    "        seed=hparams['seed']\n",
    "    )    \n",
    "\n",
    "    raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        os.path.join(dataset_dir, 'train'),\n",
    "        batch_size=hparams['batch-size'],\n",
    "        validation_split=0.2,\n",
    "        subset='validation',\n",
    "        seed=hparams['seed']\n",
    "    )\n",
    "\n",
    "    raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
    "        os.path.join(dataset_dir, 'test'),\n",
    "        batch_size=hparams['batch-size']\n",
    "    )\n",
    "    \n",
    "    return raw_train_ds, raw_val_ds, raw_test_ds\n",
    "\n",
    "def build_text_classifier(hparams, optimizer):\n",
    "    \"\"\"Define and compile a TensorFlow BERT sentiment classifier.\n",
    "    Args:\n",
    "      hparams(dict): A dictionary containing model training arguments.\n",
    "    Returns:\n",
    "      model(tf.keras.Model): A compiled TensorFlow model.\n",
    "    \"\"\"\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    \n",
    "    # Add a hub.KerasLayer for BERT text preprocessing using the hparams dict. \n",
    "    # Name the layer 'preprocessing' and store in the variable preprocessor.\n",
    "    preprocessor = hub.KerasLayer(hparams['tfhub-bert-preprocessor'], name='preprocessing')\n",
    "    encoder_inputs = preprocessor(text_input)\n",
    "    \n",
    "    # Add a trainable hub.KerasLayer for BERT text encoding using the hparams dict.\n",
    "    # Name the layer 'BERT_encoder' and store in the variable encoder.\n",
    "    encoder = hub.KerasLayer(hparams['tfhub-bert-encoder'], trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    \n",
    "    # For the fine-tuning you are going to use the `pooled_output` array which represents each input sequence as a whole. The shape is [batch_size, H]. \n",
    "    # You can think of this as an embedding for the entire movie review.\n",
    "    classifier = outputs['pooled_output']\n",
    "    \n",
    "    # Add dropout to prevent overfitting during model fine-tuning.\n",
    "    classifier = tf.keras.layers.Dropout(hparams['dropout'], name='dropout')(classifier)\n",
    "    classifier = tf.keras.layers.Dense(1, activation=None, name='classifier')(classifier)\n",
    "    model = tf.keras.Model(text_input, classifier, name='bert-sentiment-classifier')\n",
    "    \n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    metrics = tf.metrics.BinaryAccuracy()    \n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=metrics\n",
    "    )    \n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_evaluate(hparams):\n",
    "    \"\"\"Train and evaluate TensorFlow BERT sentiment classifier.\n",
    "    Args:\n",
    "      hparams(dict): A dictionary containing model training arguments.\n",
    "    Returns:\n",
    "      history(tf.keras.callbacks.History): Keras callback that records training event history.\n",
    "    \"\"\"\n",
    "    dataset_dir = download_data(data_url=DATA_URL, local_data_dir=LOCAL_DATA_DIR)\n",
    "    \n",
    "    raw_train_ds, raw_val_ds, raw_test_ds = load_datasets(dataset_dir=dataset_dir, hparams=hparams)\n",
    "    \n",
    "    train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    val_ds = raw_val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    test_ds = raw_test_ds.cache().prefetch(buffer_size=AUTOTUNE)     \n",
    "    \n",
    "    epochs = hparams['epochs']\n",
    "    steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "    n_train_steps = steps_per_epoch * epochs\n",
    "    n_warmup_steps = int(0.1 * n_train_steps)    \n",
    "    \n",
    "    optimizer = optimization.create_optimizer(\n",
    "        init_lr=hparams['initial-learning-rate'],\n",
    "        num_train_steps=n_train_steps,\n",
    "        num_warmup_steps=n_warmup_steps,\n",
    "        optimizer_type='adamw'\n",
    "    )    \n",
    "    \n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    \n",
    "    with mirrored_strategy.scope():\n",
    "        model = build_text_classifier(hparams=hparams, optimizer=optimizer)\n",
    "        logging.info(model.summary())\n",
    "        \n",
    "    history = model.fit(x=train_ds, validation_data=val_ds, epochs=epochs)  \n",
    "    \n",
    "    logging.info(\"Test accuracy: %s\", model.evaluate(test_ds))\n",
    "\n",
    "    # Export Keras model in TensorFlow SavedModel format.\n",
    "    model.save(hparams['model-dir'])\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e16b936-d93a-4411-a494-aacda93b05f4",
   "metadata": {},
   "source": [
    "### 2. Write a `task.py` file as an entrypoint to your custom model container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17517e0b-a2ac-489a-bf03-357ace5d6577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting bert-sentiment-classifier/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {MODEL_DIR}/trainer/task.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from trainer import model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # Vertex custom container training args. These are set by Vertex AI during training but can also be overwritten.\n",
    "    parser.add_argument('--model-dir', dest='model-dir', default=os.environ['AIP_MODEL_DIR'], type=str, help='GCS URI for saving model artifacts.')\n",
    "\n",
    "    # Model training args.\n",
    "    parser.add_argument('--tfhub-bert-preprocessor', dest='tfhub-bert-preprocessor', default='https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3', type=str, help='TF-Hub URL.')\n",
    "    parser.add_argument('--tfhub-bert-encoder', dest='tfhub-bert-encoder', default='https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2', type=str, help='TF-Hub URL.')    \n",
    "    parser.add_argument('--initial-learning-rate', dest='initial-learning-rate', default=3e-5, type=float, help='Learning rate for optimizer.')\n",
    "    parser.add_argument('--epochs', dest='epochs', default=3, type=int, help='Training iterations.')    \n",
    "    parser.add_argument('--batch-size', dest='batch-size', default=32, type=int, help='Number of examples during each training iteration.')    \n",
    "    parser.add_argument('--dropout', dest='dropout', default=0.1, type=float, help='Float percentage of DNN nodes [0,1] to drop for regularization.')    \n",
    "    parser.add_argument('--seed', dest='seed', default=42, type=int, help='Random number generator seed to prevent overlap between train and val sets.')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    hparams = args.__dict__\n",
    "\n",
    "    model.train_evaluate(hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d503a04a-5f15-4503-91e9-1acc4353fd08",
   "metadata": {},
   "source": [
    "### 3. Write a `Dockerfile` for your custom model container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253b0320-a3c2-4fbd-96f0-48ca3b49d485",
   "metadata": {},
   "source": [
    "Third, you will write a `Dockerfile` that contains instructions to package your model code in `bert-sentiment-classifier` as well as specifies your model code's dependencies needed for execution together in a Docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b86ede10-6372-4320-89d3-264d4d1b1ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting bert-sentiment-classifier/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile {MODEL_DIR}/Dockerfile\n",
    "\n",
    "# Specifies base image and tag.\n",
    "# https://cloud.google.com/vertex-ai/docs/training/pre-built-containers\n",
    "FROM us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-6:latest\n",
    "\n",
    "# Sets the container working directory.\n",
    "WORKDIR /root\n",
    "\n",
    "# Copies the requirements.txt into the container to reduce network calls.\n",
    "COPY requirements.txt .\n",
    "\n",
    "# Installs additional packages.\n",
    "RUN pip3 install -U -r requirements.txt\n",
    "\n",
    "# b/203105209 Removes unneeded file from TF2.5 CPU image for python_module CustomJob training. \n",
    "# Will be removed on subsequent public Vertex images.\n",
    "RUN rm -rf /var/sitecustomize/sitecustomize.py\n",
    "\n",
    "# Copies the trainer code to the docker image.\n",
    "COPY . /trainer\n",
    "\n",
    "# Sets the container working directory.\n",
    "WORKDIR /trainer\n",
    "\n",
    "# Sets up the entry point to invoke the trainer.\n",
    "ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2974866-46f7-4f16-b6c0-9ea420ea6d73",
   "metadata": {},
   "source": [
    "### 4. Write a `requirements.txt` file to specify additional ML code dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d62327-31c6-4ae5-819c-f59fb16e58c3",
   "metadata": {},
   "source": [
    "These are additional dependencies for your model code not included in the pre-built Vertex TensorFlow images such as TF-Hub, TensorFlow AdamW optimizer, and TensorFlow Text needed for importing and working with pre-trained TensorFlow BERT models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe7619e1-fff9-4a47-90a8-3ba9b55e74c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting bert-sentiment-classifier/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {MODEL_DIR}/requirements.txt\n",
    "tf-models-official==2.6.0\n",
    "tensorflow-text==2.6.0\n",
    "tensorflow-hub==0.12.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81292584-7a08-4c92-a9ba-e3dbc7005130",
   "metadata": {},
   "source": [
    "## Use Cloud Build to build and submit your model container to Google Cloud Artifact Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d47400c-aa7c-4929-a584-f5067bd682eb",
   "metadata": {},
   "source": [
    "Next, you will use [Cloud Build](https://cloud.google.com/build) to build and upload your custom TensorFlow model container to [Google Cloud Artifact Registry](https://cloud.google.com/artifact-registry).\n",
    "\n",
    "Cloud Build brings reusability and automation to your ML experimentation by enabling you to reliably build, test, and deploy your ML model code as part of a CI/CD workflow. Artifact Registry provides a centralized repository for you to store, manage, and secure your ML container images. This will allow you to securely share your ML work with others and reproduce experiment results.\n",
    "\n",
    "**Note**: the initial build and submit step will take about 16 minutes but Cloud Build is able to take advantage of caching for faster subsequent builds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860c0d02-200f-4cc3-bdfd-ba96d233ecc4",
   "metadata": {},
   "source": [
    "### 1. Create Artifact Registry for custom container images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9918475-f6dc-4fa3-8249-47976e68f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACT_REGISTRY=\"bert-sentiment-classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93d9566d-c6c4-48c8-b4f8-ad239e5ae349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create request issued for: [bert-sentiment-classifier]\n",
      "Waiting for operation [projects/qwiklabs-gcp-03-80c91a5be9c5/locations/us-centr\n",
      "al1/operations/40c0003a-4ce9-4e13-9dc7-0a6ed8bc06a2] to complete...done.       \n",
      "Created repository [bert-sentiment-classifier].\n"
     ]
    }
   ],
   "source": [
    "# TODO: create a Docker Artifact Registry using the gcloud CLI. Note the required respository-format and location flags.\n",
    "# Documentation link: https://cloud.google.com/sdk/gcloud/reference/artifacts/repositories/create\n",
    "!gcloud artifacts repositories create {ARTIFACT_REGISTRY} \\\n",
    "--repository-format=docker \\\n",
    "--location={REGION} \\\n",
    "--description=\"Artifact registry for ML custom training images for sentiment classification\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e900832e-de90-4ba1-ba7d-7973a1de9cc1",
   "metadata": {},
   "source": [
    "### 2. Create `cloudbuild.yaml` instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b580619d-957c-409f-ac15-ccbc0bb79a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME=\"bert-sentiment-classifier\"\n",
    "IMAGE_TAG=\"latest\"\n",
    "IMAGE_URI=f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{ARTIFACT_REGISTRY}/{IMAGE_NAME}:{IMAGE_TAG}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24790970-988e-4694-b8cd-a2d9d500c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudbuild_yaml = f\"\"\"steps:\n",
    "- name: 'gcr.io/cloud-builders/docker'\n",
    "  args: [ 'build', '-t', '{IMAGE_URI}', '.' ]\n",
    "images: \n",
    "- '{IMAGE_URI}'\"\"\"\n",
    "\n",
    "with open(f\"{MODEL_DIR}/cloudbuild.yaml\", \"w\") as fp: fp.write(cloudbuild_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c14b9c6-c120-482d-b5ab-c6a4c53bb205",
   "metadata": {},
   "source": [
    "### 3. Build and submit your container image to Artifact Registry using Cloud Build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e154b1-e584-496c-97b4-14795f80928b",
   "metadata": {},
   "source": [
    "**Note:** your custom model container will take about 16 minutes initially to build and submit to your Artifact Registry. Artifact Registry is able to take advantage of caching so subsequent builds take about 4 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ebf0093-d66e-49c1-8a55-047020735e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 6 file(s) totalling 8.2 KiB before compression.\n",
      "Uploading tarball of [bert-sentiment-classifier] to [gs://qwiklabs-gcp-03-80c91a5be9c5_cloudbuild/source/1657189972.256454-7ec7abca39b24c6bae37295b25d132aa.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/qwiklabs-gcp-03-80c91a5be9c5/locations/global/builds/8583667d-724f-424c-8de6-8459b9cc67e4].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/8583667d-724f-424c-8de6-8459b9cc67e4?project=460398158828].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"8583667d-724f-424c-8de6-8459b9cc67e4\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://qwiklabs-gcp-03-80c91a5be9c5_cloudbuild/source/1657189972.256454-7ec7abca39b24c6bae37295b25d132aa.tgz#1657189973146979\n",
      "Copying gs://qwiklabs-gcp-03-80c91a5be9c5_cloudbuild/source/1657189972.256454-7ec7abca39b24c6bae37295b25d132aa.tgz#1657189973146979...\n",
      "/ [1 files][  3.4 KiB/  3.4 KiB]                                                \n",
      "Operation completed over 1 objects/3.4 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  14.85kB\n",
      "Step 1/8 : FROM us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-6:latest\n",
      "latest: Pulling from vertex-ai/training/tf-cpu.2-6\n",
      "feac53061382: Pulling fs layer\n",
      "7270e73e2667: Pulling fs layer\n",
      "bdaae651af3f: Pulling fs layer\n",
      "1148834bd9d8: Pulling fs layer\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "f904f76abbe4: Pulling fs layer\n",
      "0976a87c9f48: Pulling fs layer\n",
      "076ba86c3f40: Pulling fs layer\n",
      "41c88a594c8b: Pulling fs layer\n",
      "44b22e02eb44: Pulling fs layer\n",
      "ba0435ea2ef5: Pulling fs layer\n",
      "69afaffe6a49: Pulling fs layer\n",
      "3f8a33bd180a: Pulling fs layer\n",
      "2a00d28ce456: Pulling fs layer\n",
      "9fcf01642b85: Pulling fs layer\n",
      "07c36a7fd024: Pulling fs layer\n",
      "df1aa6147fdd: Pulling fs layer\n",
      "1be9a569c2f6: Pulling fs layer\n",
      "89c9e74c9c4c: Pulling fs layer\n",
      "9c1c95c4a10c: Pulling fs layer\n",
      "43922376e3f2: Pulling fs layer\n",
      "b2867b553c8f: Pulling fs layer\n",
      "82592f4e6709: Pulling fs layer\n",
      "fe3eddb05a06: Pulling fs layer\n",
      "442cd8558cbf: Pulling fs layer\n",
      "47df1213eb7b: Pulling fs layer\n",
      "d1f8423fa1f7: Pulling fs layer\n",
      "ad9628131dde: Pulling fs layer\n",
      "d1427baf5421: Pulling fs layer\n",
      "02343499fe04: Pulling fs layer\n",
      "2cc8ae6b7bc5: Pulling fs layer\n",
      "b191036094fa: Pulling fs layer\n",
      "6bf34d10d7a4: Pulling fs layer\n",
      "1148834bd9d8: Waiting\n",
      "4f4fb700ef54: Waiting\n",
      "f904f76abbe4: Waiting\n",
      "0976a87c9f48: Waiting\n",
      "076ba86c3f40: Waiting\n",
      "41c88a594c8b: Waiting\n",
      "44b22e02eb44: Waiting\n",
      "ba0435ea2ef5: Waiting\n",
      "69afaffe6a49: Waiting\n",
      "3f8a33bd180a: Waiting\n",
      "2a00d28ce456: Waiting\n",
      "9fcf01642b85: Waiting\n",
      "07c36a7fd024: Waiting\n",
      "df1aa6147fdd: Waiting\n",
      "1be9a569c2f6: Waiting\n",
      "89c9e74c9c4c: Waiting\n",
      "9c1c95c4a10c: Waiting\n",
      "43922376e3f2: Waiting\n",
      "b2867b553c8f: Waiting\n",
      "82592f4e6709: Waiting\n",
      "fe3eddb05a06: Waiting\n",
      "442cd8558cbf: Waiting\n",
      "2cc8ae6b7bc5: Waiting\n",
      "b191036094fa: Waiting\n",
      "6bf34d10d7a4: Waiting\n",
      "d1f8423fa1f7: Waiting\n",
      "ad9628131dde: Waiting\n",
      "d1427baf5421: Waiting\n",
      "02343499fe04: Waiting\n",
      "7270e73e2667: Download complete\n",
      "feac53061382: Verifying Checksum\n",
      "feac53061382: Download complete\n",
      "4f4fb700ef54: Verifying Checksum\n",
      "4f4fb700ef54: Download complete\n",
      "f904f76abbe4: Verifying Checksum\n",
      "f904f76abbe4: Download complete\n",
      "1148834bd9d8: Verifying Checksum\n",
      "1148834bd9d8: Download complete\n",
      "076ba86c3f40: Verifying Checksum\n",
      "076ba86c3f40: Download complete\n",
      "41c88a594c8b: Verifying Checksum\n",
      "41c88a594c8b: Download complete\n",
      "44b22e02eb44: Verifying Checksum\n",
      "44b22e02eb44: Download complete\n",
      "ba0435ea2ef5: Verifying Checksum\n",
      "ba0435ea2ef5: Download complete\n",
      "69afaffe6a49: Verifying Checksum\n",
      "69afaffe6a49: Download complete\n",
      "3f8a33bd180a: Verifying Checksum\n",
      "3f8a33bd180a: Download complete\n",
      "2a00d28ce456: Verifying Checksum\n",
      "2a00d28ce456: Download complete\n",
      "9fcf01642b85: Verifying Checksum\n",
      "9fcf01642b85: Download complete\n",
      "bdaae651af3f: Verifying Checksum\n",
      "bdaae651af3f: Download complete\n",
      "0976a87c9f48: Verifying Checksum\n",
      "0976a87c9f48: Download complete\n",
      "1be9a569c2f6: Verifying Checksum\n",
      "1be9a569c2f6: Download complete\n",
      "df1aa6147fdd: Verifying Checksum\n",
      "df1aa6147fdd: Download complete\n",
      "9c1c95c4a10c: Verifying Checksum\n",
      "9c1c95c4a10c: Download complete\n",
      "feac53061382: Pull complete\n",
      "89c9e74c9c4c: Download complete\n",
      "43922376e3f2: Verifying Checksum\n",
      "43922376e3f2: Download complete\n",
      "b2867b553c8f: Verifying Checksum\n",
      "b2867b553c8f: Download complete\n",
      "82592f4e6709: Verifying Checksum\n",
      "82592f4e6709: Download complete\n",
      "7270e73e2667: Pull complete\n",
      "442cd8558cbf: Download complete\n",
      "47df1213eb7b: Verifying Checksum\n",
      "47df1213eb7b: Download complete\n",
      "d1f8423fa1f7: Verifying Checksum\n",
      "d1f8423fa1f7: Download complete\n",
      "fe3eddb05a06: Verifying Checksum\n",
      "fe3eddb05a06: Download complete\n",
      "d1427baf5421: Verifying Checksum\n",
      "d1427baf5421: Download complete\n",
      "02343499fe04: Verifying Checksum\n",
      "02343499fe04: Download complete\n",
      "2cc8ae6b7bc5: Verifying Checksum\n",
      "2cc8ae6b7bc5: Download complete\n",
      "b191036094fa: Verifying Checksum\n",
      "b191036094fa: Download complete\n",
      "6bf34d10d7a4: Download complete\n",
      "ad9628131dde: Verifying Checksum\n",
      "ad9628131dde: Download complete\n",
      "07c36a7fd024: Verifying Checksum\n",
      "07c36a7fd024: Download complete\n",
      "bdaae651af3f: Pull complete\n",
      "1148834bd9d8: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "f904f76abbe4: Pull complete\n",
      "0976a87c9f48: Pull complete\n",
      "076ba86c3f40: Pull complete\n",
      "41c88a594c8b: Pull complete\n",
      "44b22e02eb44: Pull complete\n",
      "ba0435ea2ef5: Pull complete\n",
      "69afaffe6a49: Pull complete\n",
      "3f8a33bd180a: Pull complete\n",
      "2a00d28ce456: Pull complete\n",
      "9fcf01642b85: Pull complete\n",
      "07c36a7fd024: Pull complete\n",
      "df1aa6147fdd: Pull complete\n",
      "1be9a569c2f6: Pull complete\n",
      "89c9e74c9c4c: Pull complete\n",
      "9c1c95c4a10c: Pull complete\n",
      "43922376e3f2: Pull complete\n",
      "b2867b553c8f: Pull complete\n",
      "82592f4e6709: Pull complete\n",
      "fe3eddb05a06: Pull complete\n",
      "442cd8558cbf: Pull complete\n",
      "47df1213eb7b: Pull complete\n",
      "d1f8423fa1f7: Pull complete\n",
      "ad9628131dde: Pull complete\n",
      "d1427baf5421: Pull complete\n",
      "02343499fe04: Pull complete\n",
      "2cc8ae6b7bc5: Pull complete\n",
      "b191036094fa: Pull complete\n",
      "6bf34d10d7a4: Pull complete\n",
      "Digest: sha256:9579635bb22888024df279dcda1a82f23dfdb42022f8a352eb8774e2c0b7a3c6\n",
      "Status: Downloaded newer image for us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-6:latest\n",
      " ---> 6828de55ad33\n",
      "Step 2/8 : WORKDIR /root\n",
      " ---> Running in 5d7a93735460\n",
      "Removing intermediate container 5d7a93735460\n",
      " ---> 485d010a8c3b\n",
      "Step 3/8 : COPY requirements.txt .\n",
      " ---> 6b1d3ed4d4ec\n",
      "Step 4/8 : RUN pip3 install -U -r requirements.txt\n",
      " ---> Running in 74e1c92dd2fe\n",
      "Collecting tf-models-official==2.6.0\n",
      "  Downloading tf_models_official-2.6.0-py2.py3-none-any.whl (1.8 MB)\n",
      "Collecting tensorflow-text==2.6.0\n",
      "  Downloading tensorflow_text-2.6.0-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n",
      "Requirement already satisfied: tensorflow-hub==0.12.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (0.12.0)\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.1.0-py3-none-any.whl (92 kB)\n",
      "Requirement already satisfied: tensorflow>=2.5.0 in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.6.0->-r requirements.txt (line 1)) (2.6.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.6.0->-r requirements.txt (line 1)) (2.15.0)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.6.0->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: oauth2client in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.6.0->-r requirements.txt (line 1)) (4.1.3)\n",
      "Collecting tensorflow-model-optimization>=0.4.1\n",
      "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.6.0->-r requirements.txt (line 1)) (5.4.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.6.0->-r requirements.txt (line 1)) (1.7.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.6.0->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.6.0->-r requirements.txt (line 1)) (1.19.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.6.0->-r requirements.txt (line 1)) (1.16.0)\n",
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.4.tar.gz (106 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting tf-slim>=1.1.0\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.6.0->-r requirements.txt (line 1)) (5.8.0)\n",
      "Collecting Cython\n",
      "  Using cached Cython-0.29.30-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "Collecting gin-config\n",
      "  Downloading gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "Collecting py-cpuinfo>=3.3.0\n",
      "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.6.0->-r requirements.txt (line 1)) (8.3.1)\n",
      "Collecting kaggle>=1.3.9\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "Requirement already satisfied: tensorflow-datasets in /opt/conda/lib/python3.7/site-packages (from tf-models-official==2.6.0->-r requirements.txt (line 1)) (4.3.0)\n",
      "Collecting opencv-python-headless\n",
      "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-hub==0.12.0->-r requirements.txt (line 3)) (3.16.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.6.0->-r requirements.txt (line 1)) (1.34.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=1.21.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.6.0->-r requirements.txt (line 1)) (1.31.1)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.6.0->-r requirements.txt (line 1)) (0.19.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.6.0->-r requirements.txt (line 1)) (0.1.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client>=1.6.7->tf-models-official==2.6.0->-r requirements.txt (line 1)) (3.0.1)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.6.0->-r requirements.txt (line 1)) (21.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.6.0->-r requirements.txt (line 1)) (1.53.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.6.0->-r requirements.txt (line 1)) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.6.0->-r requirements.txt (line 1)) (49.6.0.post20210108)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.6.0->-r requirements.txt (line 1)) (2021.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.6.0->-r requirements.txt (line 1)) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.6.0->-r requirements.txt (line 1)) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.6.0->-r requirements.txt (line 1)) (4.2.2)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client>=1.6.7->tf-models-official==2.6.0->-r requirements.txt (line 1)) (2.4.7)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kaggle>=1.3.9->tf-models-official==2.6.0->-r requirements.txt (line 1)) (2021.5.30)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kaggle>=1.3.9->tf-models-official==2.6.0->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from kaggle>=1.3.9->tf-models-official==2.6.0->-r requirements.txt (line 1)) (4.62.0)\n",
      "Requirement already satisfied: python-slugify in /opt/conda/lib/python3.7/site-packages (from kaggle>=1.3.9->tf-models-official==2.6.0->-r requirements.txt (line 1)) (5.0.2)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from kaggle>=1.3.9->tf-models-official==2.6.0->-r requirements.txt (line 1)) (1.26.6)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.6.0->-r requirements.txt (line 1)) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.6.0->-r requirements.txt (line 1)) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3.0.0dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.6.0->-r requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: absl-py~=0.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (0.13.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (1.12)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (0.37.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (1.38.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: keras~=2.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (2.6.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (3.3.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (1.1.2)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (1.12.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (3.1.0)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (2.6.0)\n",
      "Requirement already satisfied: clang~=5.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (5.0)\n",
      "Collecting six\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (1.5.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (0.4.5)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (3.3.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (4.6.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (3.1.1)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.6.0->-r requirements.txt (line 1)) (0.1.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official==2.6.0->-r requirements.txt (line 1)) (3.5.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->tf-models-official==2.6.0->-r requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->tf-models-official==2.6.0->-r requirements.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /opt/conda/lib/python3.7/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.6.0->-r requirements.txt (line 1)) (1.3)\n",
      "Collecting tabulate>=0.8.9\n",
      "  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from sacrebleu->tf-models-official==2.6.0->-r requirements.txt (line 1)) (0.4.4)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from sacrebleu->tf-models-official==2.6.0->-r requirements.txt (line 1)) (2021.8.3)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from seqeval->tf-models-official==2.6.0->-r requirements.txt (line 1)) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.6.0->-r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.6.0->-r requirements.txt (line 1)) (2.2.0)\n",
      "Collecting typeguard>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official==2.6.0->-r requirements.txt (line 1)) (5.2.2)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official==2.6.0->-r requirements.txt (line 1)) (0.3.4)\n",
      "Requirement already satisfied: promise in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official==2.6.0->-r requirements.txt (line 1)) (2.3)\n",
      "Requirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official==2.6.0->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official==2.6.0->-r requirements.txt (line 1)) (21.2.0)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from tensorflow-datasets->tf-models-official==2.6.0->-r requirements.txt (line 1)) (0.18.2)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "Building wheels for collected packages: kaggle, py-cpuinfo, pycocotools, seqeval\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73052 sha256=4a1d6cb31ea7070878391693c005030ce1a928089a442a407249c2c69a422170\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n",
      "  Building wheel for py-cpuinfo (setup.py): started\n",
      "  Building wheel for py-cpuinfo (setup.py): finished with status 'done'\n",
      "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22244 sha256=1cb1ee1a2a2a19a8e2d15e14411034a4ebd27e026354c21aa7f7e261391c7fdd\n",
      "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
      "  Building wheel for pycocotools (PEP 517): started\n",
      "  Building wheel for pycocotools (PEP 517): finished with status 'done'\n",
      "  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp37-cp37m-linux_x86_64.whl size=273633 sha256=756354323650f54a1ce3a53315a516779da23dbd2e57bca45f7c19f12aeb3367\n",
      "  Stored in directory: /root/.cache/pip/wheels/a3/5f/fa/f011e578cc76e1fc5be8dce30b3eb9fd00f337e744b3bba59b\n",
      "  Building wheel for seqeval (setup.py): started\n",
      "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16171 sha256=2147f188efa419105e0ccefc5cb177e05c7c1df768fbfcf1781947ea31de5329\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
      "Successfully built kaggle py-cpuinfo pycocotools seqeval\n",
      "Installing collected packages: typing-extensions, six, absl-py, tensorboard, typeguard, tabulate, portalocker, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pycocotools, py-cpuinfo, opencv-python-headless, kaggle, gin-config, Cython, tf-models-official\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.0\n",
      "    Uninstalling typing-extensions-3.10.0.0:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.0\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.13.0\n",
      "    Uninstalling absl-py-0.13.0:\n",
      "      Successfully uninstalled absl-py-0.13.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-io 0.18.0 requires tensorflow-io-gcs-filesystem==0.18.0, which is not installed.\n",
      "tfx-bsl 1.2.0 requires google-api-python-client<2,>=1.7.11, but you have google-api-python-client 2.15.0 which is incompatible.\n",
      "tfx-bsl 1.2.0 requires google-cloud-bigquery<2.21,>=1.28.0, but you have google-cloud-bigquery 2.23.3 which is incompatible.\n",
      "tfx-bsl 1.2.0 requires pyarrow<3,>=1, but you have pyarrow 5.0.0 which is incompatible.\n",
      "tensorflow-transform 1.2.0 requires google-cloud-bigquery<2.21,>=1.28.0, but you have google-cloud-bigquery 2.23.3 which is incompatible.\n",
      "tensorflow-transform 1.2.0 requires pyarrow<3,>=1, but you have pyarrow 5.0.0 which is incompatible.\n",
      "tensorflow-transform 1.2.0 requires tensorflow!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,<2.6,>=1.15.2, but you have tensorflow 2.6.0 which is incompatible.\n",
      "tensorflow-io 0.18.0 requires tensorflow<2.6.0,>=2.5.0, but you have tensorflow 2.6.0 which is incompatible.\n",
      "cloud-tpu-client 0.10 requires google-api-python-client==1.8.0, but you have google-api-python-client 2.15.0 which is incompatible.\n",
      "apache-beam 2.31.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.4 which is incompatible.\n",
      "apache-beam 2.31.0 requires pyarrow<5.0.0,>=0.15.1, but you have pyarrow 5.0.0 which is incompatible.\n",
      "\u001b[0m\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mSuccessfully installed Cython-0.29.30 absl-py-0.12.0 gin-config-0.5.0 kaggle-1.5.12 opencv-python-headless-4.6.0.66 portalocker-2.4.0 py-cpuinfo-8.0.0 pycocotools-2.0.4 sacrebleu-2.1.0 sentencepiece-0.1.96 seqeval-1.2.2 six-1.15.0 tabulate-0.8.10 tensorboard-2.9.1 tensorflow-addons-0.17.1 tensorflow-model-optimization-0.7.2 tensorflow-text-2.6.0 tf-models-official-2.6.0 tf-slim-1.1.0 typeguard-2.13.3 typing-extensions-3.7.4.3\n",
      "Removing intermediate container 74e1c92dd2fe\n",
      " ---> d1e4f7927409\n",
      "Step 5/8 : RUN rm -rf /var/sitecustomize/sitecustomize.py\n",
      " ---> Running in 6a10b97088df\n",
      "Removing intermediate container 6a10b97088df\n",
      " ---> e1fbcd293b44\n",
      "Step 6/8 : COPY . /trainer\n",
      " ---> 0eaa304bd4b1\n",
      "Step 7/8 : WORKDIR /trainer\n",
      " ---> Running in 10868df6f8a8\n",
      "Removing intermediate container 10868df6f8a8\n",
      " ---> a421eaf90dd8\n",
      "Step 8/8 : ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]\n",
      " ---> Running in 82d9e57c527e\n",
      "Removing intermediate container 82d9e57c527e\n",
      " ---> 1f4aeec27d58\n",
      "Successfully built 1f4aeec27d58\n",
      "Successfully tagged us-central1-docker.pkg.dev/qwiklabs-gcp-03-80c91a5be9c5/bert-sentiment-classifier/bert-sentiment-classifier:latest\n",
      "PUSH\n",
      "Pushing us-central1-docker.pkg.dev/qwiklabs-gcp-03-80c91a5be9c5/bert-sentiment-classifier/bert-sentiment-classifier:latest\n",
      "The push refers to repository [us-central1-docker.pkg.dev/qwiklabs-gcp-03-80c91a5be9c5/bert-sentiment-classifier/bert-sentiment-classifier]\n",
      "0d3db5379301: Preparing\n",
      "919d9b313ed0: Preparing\n",
      "e157ca29ef97: Preparing\n",
      "07048354f283: Preparing\n",
      "4c57c3a2fee3: Preparing\n",
      "4c57c3a2fee3: Preparing\n",
      "3dbbc650d5f7: Preparing\n",
      "36c24ce2bec5: Preparing\n",
      "c2847b26212d: Preparing\n",
      "d561bc3142f2: Preparing\n",
      "d561bc3142f2: Preparing\n",
      "53cbd511028e: Preparing\n",
      "5d997b799243: Preparing\n",
      "0d3c6842b77f: Preparing\n",
      "03def71a48c7: Preparing\n",
      "032183a1c75b: Preparing\n",
      "403a518d2b71: Preparing\n",
      "3a88469d4264: Preparing\n",
      "301ef6e29a84: Preparing\n",
      "301ef6e29a84: Preparing\n",
      "c78df0c3ce3c: Preparing\n",
      "27818657c8ea: Preparing\n",
      "e19df3f0bc61: Preparing\n",
      "b70384cdcd53: Preparing\n",
      "7a978fe462d3: Preparing\n",
      "b3cd582c8414: Preparing\n",
      "eb362fcdb550: Preparing\n",
      "f626fcf5cda1: Preparing\n",
      "94d6a6645274: Preparing\n",
      "18803adcd9d2: Preparing\n",
      "a9c44eca1563: Preparing\n",
      "fb04b4bc0668: Preparing\n",
      "e5ccc73dfc63: Preparing\n",
      "bad38e4795f1: Preparing\n",
      "ffbd9d96e302: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "b52f88b681cd: Preparing\n",
      "355ea46b9ff5: Preparing\n",
      "ccc9e6413c69: Preparing\n",
      "21639b09744f: Preparing\n",
      "3dbbc650d5f7: Waiting\n",
      "b3cd582c8414: Waiting\n",
      "eb362fcdb550: Waiting\n",
      "f626fcf5cda1: Waiting\n",
      "94d6a6645274: Waiting\n",
      "18803adcd9d2: Waiting\n",
      "a9c44eca1563: Waiting\n",
      "fb04b4bc0668: Waiting\n",
      "e5ccc73dfc63: Waiting\n",
      "bad38e4795f1: Waiting\n",
      "ffbd9d96e302: Waiting\n",
      "5f70bf18a086: Waiting\n",
      "b52f88b681cd: Waiting\n",
      "355ea46b9ff5: Waiting\n",
      "c2847b26212d: Waiting\n",
      "d561bc3142f2: Waiting\n",
      "ccc9e6413c69: Waiting\n",
      "21639b09744f: Waiting\n",
      "53cbd511028e: Waiting\n",
      "5d997b799243: Waiting\n",
      "0d3c6842b77f: Waiting\n",
      "c78df0c3ce3c: Waiting\n",
      "27818657c8ea: Waiting\n",
      "03def71a48c7: Waiting\n",
      "e19df3f0bc61: Waiting\n",
      "032183a1c75b: Waiting\n",
      "b70384cdcd53: Waiting\n",
      "403a518d2b71: Waiting\n",
      "7a978fe462d3: Waiting\n",
      "301ef6e29a84: Waiting\n",
      "3a88469d4264: Waiting\n",
      "919d9b313ed0: Pushed\n",
      "07048354f283: Pushed\n",
      "0d3db5379301: Pushed\n",
      "4c57c3a2fee3: Pushed\n",
      "36c24ce2bec5: Pushed\n",
      "3dbbc650d5f7: Pushed\n",
      "c2847b26212d: Pushed\n",
      "d561bc3142f2: Pushed\n",
      "5d997b799243: Pushed\n",
      "53cbd511028e: Pushed\n",
      "03def71a48c7: Pushed\n",
      "403a518d2b71: Pushed\n",
      "3a88469d4264: Pushed\n",
      "301ef6e29a84: Pushed\n",
      "c78df0c3ce3c: Pushed\n",
      "27818657c8ea: Pushed\n",
      "e19df3f0bc61: Pushed\n",
      "b70384cdcd53: Pushed\n",
      "b3cd582c8414: Pushed\n",
      "eb362fcdb550: Pushed\n",
      "f626fcf5cda1: Pushed\n",
      "94d6a6645274: Pushed\n",
      "18803adcd9d2: Pushed\n",
      "a9c44eca1563: Pushed\n",
      "fb04b4bc0668: Pushed\n",
      "e5ccc73dfc63: Pushed\n",
      "e157ca29ef97: Pushed\n",
      "ffbd9d96e302: Pushed\n",
      "5f70bf18a086: Layer already exists\n",
      "0d3c6842b77f: Pushed\n",
      "bad38e4795f1: Pushed\n",
      "ccc9e6413c69: Pushed\n",
      "21639b09744f: Pushed\n",
      "032183a1c75b: Pushed\n",
      "b52f88b681cd: Pushed\n",
      "355ea46b9ff5: Pushed\n",
      "7a978fe462d3: Pushed\n",
      "latest: digest: sha256:7a53947da6c23466d8714ea57e737b0032a5dec506be9bb1c5f9aebdec68010c size: 8670\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                      IMAGES                                                                                                                 STATUS\n",
      "8583667d-724f-424c-8de6-8459b9cc67e4  2022-07-07T10:32:53+00:00  16M26S    gs://qwiklabs-gcp-03-80c91a5be9c5_cloudbuild/source/1657189972.256454-7ec7abca39b24c6bae37295b25d132aa.tgz  us-central1-docker.pkg.dev/qwiklabs-gcp-03-80c91a5be9c5/bert-sentiment-classifier/bert-sentiment-classifier (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# TODO: use Cloud Build to build and submit your custom model container to your Artifact Registry.\n",
    "# Documentation link: https://cloud.google.com/sdk/gcloud/reference/builds/submit\n",
    "# Hint: make sure the config flag is pointed at {MODEL_DIR}/cloudbuild.yaml defined above and you include your model directory.\n",
    "!gcloud builds submit {MODEL_DIR} --timeout=20m --config {MODEL_DIR}/cloudbuild.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cee35ac-ab83-472d-ab18-f622f3e3bc31",
   "metadata": {},
   "source": [
    "## Define a pipeline using the KFP V2 SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5556979-3583-44fd-86df-d30fab8d9464",
   "metadata": {},
   "source": [
    "To address your business requirements and get your higher performing model into production to deliver value faster, you will define a pipeline using the [**Kubeflow Pipelines (KFP) V2 SDK**](https://www.kubeflow.org/docs/components/pipelines/sdk/v2/v2-compatibility) to orchestrate the training and deployment of your model on [**Vertex Pipelines**](https://cloud.google.com/vertex-ai/docs/pipelines) below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aef0e36b-3cb8-4660-bbb1-a5dcca49aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# google_cloud_pipeline_components includes pre-built KFP components for interfacing with Vertex AI services.\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from kfp.v2 import dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c95f7070-d6e5-47ab-a860-d6a7e7892164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model display name: bert-sentiment-20220707104924\n",
      "GCS dir for model training artifacts: gs://qwiklabs-gcp-03-80c91a5be9c5-vertex-challenge-lab/bert-sentiment-classifier-20220707104924\n",
      "GCS dir for pipeline artifacts: gs://qwiklabs-gcp-03-80c91a5be9c5-vertex-challenge-lab/pipeline_root/qwiklabsdemo\n"
     ]
    }
   ],
   "source": [
    "TIMESTAMP=datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "DISPLAY_NAME = \"bert-sentiment-{}\".format(TIMESTAMP)\n",
    "GCS_BASE_OUTPUT_DIR= f\"{GCS_BUCKET}/{MODEL_DIR}-{TIMESTAMP}\"\n",
    "\n",
    "# TODO: change this to your name.\n",
    "USER = \"qwiklabsdemo\"\n",
    "\n",
    "PIPELINE_ROOT = \"{}/pipeline_root/{}\".format(GCS_BUCKET, USER)\n",
    "\n",
    "print(f\"Model display name: {DISPLAY_NAME}\")\n",
    "print(f\"GCS dir for model training artifacts: {GCS_BASE_OUTPUT_DIR}\")\n",
    "print(f\"GCS dir for pipeline artifacts: {PIPELINE_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4aecd42-c969-4ce0-a49a-9150c45a91e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-built Vertex model serving container for deployment.\n",
    "# https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers\n",
    "SERVING_IMAGE_URI = \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-6:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5e8dbc-04b3-4193-87f5-984d2b98a2d0",
   "metadata": {},
   "source": [
    "The pipeline consists of three components:\n",
    "\n",
    "* `CustomContainerTrainingJobRunOp` [(documentation)](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-0.2.0/google_cloud_pipeline_components.aiplatform.html#google_cloud_pipeline_components.aiplatform.CustomContainerTrainingJobRunOp): trains your custom model container using Vertex Training. This is the same as configuring a Vertex Custom Container Training Job using the Vertex Python SDK you covered in the Vertex AI: Qwik Start lab.\n",
    "\n",
    "*  `EndpointCreateOp` [(documentation)](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-0.2.0/google_cloud_pipeline_components.aiplatform.html#google_cloud_pipeline_components.aiplatform.EndpointCreateOp): Creates a Google Cloud Vertex Endpoint resource that maps physical machine resources with your model to enable it to serve online predictions. Online predictions have low latency requirements; providing resources to the model in advance reduces latency. \n",
    "\n",
    "* `ModelDeployOp`[(documentation)](https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-0.2.0/google_cloud_pipeline_components.aiplatform.html#google_cloud_pipeline_components.aiplatform.ModelDeployOp): deploys your model to a Vertex Prediction Endpoint for online predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d2181f3d-10cd-49c8-8e2f-e5c314940321",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"bert-sentiment-classification\", pipeline_root=PIPELINE_ROOT)\n",
    "def pipeline(\n",
    "    project: str = PROJECT_ID,\n",
    "    location: str = REGION,\n",
    "    staging_bucket: str = GCS_BUCKET,\n",
    "    display_name: str = DISPLAY_NAME,    \n",
    "    container_uri: str = IMAGE_URI,\n",
    "    model_serving_container_image_uri: str = SERVING_IMAGE_URI,    \n",
    "    base_output_dir: str = GCS_BASE_OUTPUT_DIR\n",
    "):\n",
    "    \n",
    "    # TODO: add and configure the pre-built KFP CustomContainerTrainingJobRunOp component using the remaining arguments in the pipeline constructor. \n",
    "    # Hint: Refer to the component documentation link above if needed as well.\n",
    "    model_train_evaluate_op = gcc_aip.CustomContainerTrainingJobRunOp(\n",
    "        \n",
    "        # Vertex AI Python SDK authentication parameters.        \n",
    "        project=project,\n",
    "        location=location,\n",
    "        staging_bucket=staging_bucket,\n",
    "        \n",
    "        # WorkerPool arguments.\n",
    "        replica_count=1,\n",
    "        machine_type=\"c2-standard-4\",\n",
    "        \n",
    "        # TODO: fill in the remaining arguments from the pipeline constructor.\n",
    "        display_name=display_name,\n",
    "        container_uri=container_uri,\n",
    "        model_serving_container_image_uri=model_serving_container_image_uri,\n",
    "        base_output_dir=GCS_BASE_OUTPUT_DIR\n",
    "    )    \n",
    "    \n",
    "    # Create a Vertex Endpoint resource in parallel with model training.\n",
    "    endpoint_create_op = gcc_aip.EndpointCreateOp(\n",
    "        \n",
    "        # Vertex AI Python SDK authentication parameters.\n",
    "        project=project,\n",
    "        location=location,\n",
    "        display_name=display_name\n",
    "    )   \n",
    "    \n",
    "    # Deploy your model to the created Endpoint resource for online predictions.\n",
    "    model_deploy_op = gcc_aip.ModelDeployOp(\n",
    "        \n",
    "        model=model_train_evaluate_op.outputs[\"model\"],    # Link to model training component through output model artifact.\n",
    "        endpoint=endpoint_create_op.outputs[\"endpoint\"],   # Link to the created Endpoint.        \n",
    "        traffic_split={\"0\": 100},                          # Define prediction request routing. {\"0\": 100} indicates 100% of traffic to the ID of the current model being deployed.\n",
    "        \n",
    "        # WorkerPool arguments.        \n",
    "        dedicated_resources_machine_type=\"n1-standard-4\",\n",
    "        dedicated_resources_min_replica_count=1,\n",
    "        dedicated_resources_max_replica_count=2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783114fd-731b-4bad-bbe2-7a858e621fca",
   "metadata": {},
   "source": [
    "## Compile the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb28dac2-3721-4fe6-9e01-98745b0d1aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2 import compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "77355b83-577b-4831-9862-91e08e974256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1266: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline,\n",
    "    package_path=\"bert-sentiment-classification.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793cda30-4046-4d29-abdd-501c243f5eee",
   "metadata": {},
   "source": [
    "## Run the pipeline on Vertex Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35be420d-9d1d-4e8e-a08a-658fdfd60eb0",
   "metadata": {},
   "source": [
    "The `PipelineJob` is configured below and triggered through the `run()` method.\n",
    "\n",
    "**Note:** This pipeline run will take around 30-40 minutes to train and deploy your model. Follow along with the execution using the URL from the job output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f276575d-c2ba-4d08-9a2a-b7583af27aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_pipelines_job = vertexai.pipeline_jobs.PipelineJob(\n",
    "    display_name=\"bert-sentiment-classification\",\n",
    "    template_path=\"bert-sentiment-classification.json\",\n",
    "    parameter_values={\n",
    "        \"project\": PROJECT_ID,\n",
    "        \"location\": REGION,\n",
    "        \"staging_bucket\": GCS_BUCKET,\n",
    "        \"display_name\": DISPLAY_NAME,        \n",
    "        \"container_uri\": IMAGE_URI,\n",
    "        \"model_serving_container_image_uri\": SERVING_IMAGE_URI,        \n",
    "        \"base_output_dir\": GCS_BASE_OUTPUT_DIR\n",
    "    },\n",
    "    enable_caching=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0ab35e9-207c-49ea-8a27-6e6cddce8541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/460398158828/locations/us-central1/pipelineJobs/bert-sentiment-classification-20220707104924\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/460398158828/locations/us-central1/pipelineJobs/bert-sentiment-classification-20220707104924')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/bert-sentiment-classification-20220707104924?project=460398158828\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/460398158828/locations/us-central1/pipelineJobs/bert-sentiment-classification-20220707104924 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/460398158828/locations/us-central1/pipelineJobs/bert-sentiment-classification-20220707104924 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/460398158828/locations/us-central1/pipelineJobs/bert-sentiment-classification-20220707104924 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/460398158828/locations/us-central1/pipelineJobs/bert-sentiment-classification-20220707104924 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/460398158828/locations/us-central1/pipelineJobs/bert-sentiment-classification-20220707104924 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/460398158828/locations/us-central1/pipelineJobs/bert-sentiment-classification-20220707104924 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/460398158828/locations/us-central1/pipelineJobs/bert-sentiment-classification-20220707104924 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/460398158828/locations/us-central1/pipelineJobs/bert-sentiment-classification-20220707104924 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/460398158828/locations/us-central1/pipelineJobs/bert-sentiment-classification-20220707104924 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/460398158828/locations/us-central1/pipelineJobs/bert-sentiment-classification-20220707104924 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/460398158828/locations/us-central1/pipelineJobs/bert-sentiment-classification-20220707104924 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob run completed. Resource name: projects/460398158828/locations/us-central1/pipelineJobs/bert-sentiment-classification-20220707104924\n"
     ]
    }
   ],
   "source": [
    "vertex_pipelines_job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319a821a-a3bd-45bf-a9ea-aa18687218f6",
   "metadata": {},
   "source": [
    "## Query deployed model on Vertex Endpoint for online predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfd8366-d362-4537-ab30-21c21fce6846",
   "metadata": {},
   "source": [
    "Finally, you will retrieve the `Endpoint` deployed by the pipeline and use it to query your model for online predictions.\n",
    "\n",
    "Configure the `Endpoint()` function below with the following parameters:\n",
    "\n",
    "*  `endpoint_name`: A fully-qualified endpoint resource name or endpoint ID. Example: \"projects/123/locations/us-central1/endpoints/456\" or \"456\" when project and location are initialized or passed.\n",
    "*  `project_id`: GCP project.\n",
    "*  `location`: GCP region.\n",
    "\n",
    "Call `predict()` to return a prediction for a test review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bf80748b-8907-4ad6-8adb-d4c394752257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve your deployed Endpoint name from your pipeline.\n",
    "ENDPOINT_NAME = vertexai.Endpoint.list()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c67c989d-1026-4f57-8dac-dafad01145a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Generate online predictions using your Vertex Endpoint.\n",
    "\n",
    "endpoint = vertexai.Endpoint(\n",
    "    endpoint_name=ENDPOINT_NAME,\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "97759f45-e060-44ce-87fc-4d34c4b8cadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: write a movie review to test your model e.g. \"The Dark Knight is the best Batman movie!\"\n",
    "test_review = \"The Dark Knight is the best Batman movie!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71c008ce-90ad-4709-a24f-36b414c779e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use your Endpoint to return prediction for your test_review.\n",
    "prediction = endpoint.predict([test_review])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54751a3e-7b2a-4ab8-b642-6533df27de82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(predictions=[[2.82785487]], deployed_model_id='6975869114610876416', explanations=None)\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4a4c68e-a937-44f8-b64a-cbe9e607cb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.9441626], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Use a sigmoid function to compress your model output between 0 and 1. For binary classification, a threshold of 0.5 is typically applied\n",
    "# so if the output is >= 0.5 then the predicted sentiment is \"Positive\" and < 0.5 is a \"Negative\" prediction.\n",
    "print(tf.sigmoid(prediction.predictions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5344e3eb-0a0e-4271-b815-e792d8c95b66",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80557132-f0cf-4f4d-be5d-2c58453bc6b6",
   "metadata": {},
   "source": [
    "Congratulations! You walked through a full experimentation, containerization, and MLOps workflow on Vertex AI. First, you built, trained, and evaluated a BERT sentiment classifier model in a Vertex Notebook. You then packaged your model code into a Docker container to train on Google Cloud's Vertex AI. Lastly, you defined and ran a Kubeflow Pipeline on Vertex Pipelines that trained and deployed your model container to a Vertex Endpoint that you queried for online predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6570ed8-a1ae-41e0-8a0b-9b63ca972d85",
   "metadata": {},
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eff0e924-7a27-4489-847f-e65b45c74d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
